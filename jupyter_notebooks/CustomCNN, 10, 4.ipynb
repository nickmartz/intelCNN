{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras Packages\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing CNN Layers\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mmartz/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# First Convolution\n",
    "# 64 Filters which are 3x3\n",
    "# Input image sizes are formatted 150x150 and 3 channels (Red, Blue, Green)\n",
    "# Using ReLU for our activation function\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), input_shape = (150, 150, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling Layer 2x2\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Convolution\n",
    "# 32 Filters which are 3x3\n",
    "# Input image sizes are formatted 150x150 and 3 channels (Red, Blue, Green)\n",
    "# Using ReLU for our activation function\n",
    "#model.add(Conv2D(32, kernel_size=(3, 3), input_shape = (150, 150, 3), activation = 'relu'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling Layer 2x2\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connecting Layer\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "# Return a categorical outcome\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7057 images belonging to 3 classes.\n",
      "Found 1509 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Fitting the CNN to the images\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/seg_train',\n",
    "                                                 target_size = (150, 150),\n",
    "                                                 batch_size = 4,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/seg_test',\n",
    "                                            target_size = (150, 150),\n",
    "                                            batch_size = 4,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "378/378 [==============================] - 28s 74ms/step - loss: 0.2947 - acc: 0.8694\n",
      "1765/1765 [==============================] - 467s 264ms/step - loss: 0.4470 - acc: 0.8144 - val_loss: 0.2947 - val_acc: 0.8694\n",
      "Epoch 2/10\n",
      "378/378 [==============================] - 24s 64ms/step - loss: 0.3034 - acc: 0.8834\n",
      "1765/1765 [==============================] - 435s 246ms/step - loss: 0.3845 - acc: 0.8423 - val_loss: 0.3034 - val_acc: 0.8834\n",
      "Epoch 3/10\n",
      "378/378 [==============================] - 24s 63ms/step - loss: 0.2934 - acc: 0.8801\n",
      "1765/1765 [==============================] - 465s 263ms/step - loss: 0.3367 - acc: 0.8715 - val_loss: 0.2934 - val_acc: 0.8801\n",
      "Epoch 4/10\n",
      "378/378 [==============================] - 25s 66ms/step - loss: 0.2388 - acc: 0.9092\n",
      "1765/1765 [==============================] - 427s 242ms/step - loss: 0.3017 - acc: 0.8824 - val_loss: 0.2388 - val_acc: 0.9092\n",
      "Epoch 5/10\n",
      "378/378 [==============================] - 23s 61ms/step - loss: 0.2434 - acc: 0.8993\n",
      "1765/1765 [==============================] - 433s 245ms/step - loss: 0.2600 - acc: 0.9008 - val_loss: 0.2434 - val_acc: 0.8993\n",
      "Epoch 6/10\n",
      "378/378 [==============================] - 23s 61ms/step - loss: 0.2192 - acc: 0.9178\n",
      "1765/1765 [==============================] - 430s 244ms/step - loss: 0.2460 - acc: 0.9082 - val_loss: 0.2192 - val_acc: 0.9178\n",
      "Epoch 7/10\n",
      "378/378 [==============================] - 24s 62ms/step - loss: 0.2393 - acc: 0.9165\n",
      "1765/1765 [==============================] - 421s 238ms/step - loss: 0.2220 - acc: 0.9184 - val_loss: 0.2393 - val_acc: 0.9165\n",
      "Epoch 8/10\n",
      "378/378 [==============================] - 26s 69ms/step - loss: 0.1843 - acc: 0.9284\n",
      "1765/1765 [==============================] - 419s 237ms/step - loss: 0.2176 - acc: 0.9151 - val_loss: 0.1843 - val_acc: 0.9284\n",
      "Epoch 9/10\n",
      "378/378 [==============================] - 21s 57ms/step - loss: 0.2326 - acc: 0.9192\n",
      "1765/1765 [==============================] - 405s 229ms/step - loss: 0.2048 - acc: 0.9239 - val_loss: 0.2326 - val_acc: 0.9192\n",
      "Epoch 10/10\n",
      "378/378 [==============================] - 21s 55ms/step - loss: 0.2246 - acc: 0.9192\n",
      "1765/1765 [==============================] - 379s 214ms/step - loss: 0.1832 - acc: 0.9355 - val_loss: 0.2246 - val_acc: 0.9192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x108e91630>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_set,\n",
    "                    epochs = 10,\n",
    "                    validation_data = test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
